"""
preprocess.py (ì‹œê°„ ìœˆë„ìš° ë³‘í•© ë²„ì „)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
improvements:
- 20-30ì´ˆ ë‹¨ìœ„ë¡œ ìë§‰ ë³‘í•©
- ì¤‘ë³µ í…ìŠ¤íŠ¸ ì œê±° (ìˆœì°¨ì )
- ì™„ì „í•œ ë¬¸ë§¥ ë³´ì¡´
"""

import webvtt
import os
import pandas as pd
from tqdm import tqdm
import re


RAW_ROOT = "data/raw"
CLEAN_ROOT = "data/clean/startup/"
LOG_ROOT = "data/clean/logs"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë¡œê·¸ ê´€ë¦¬ (ê¸°ì¡´ ìœ ì§€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_processed_ids(domain):
    """ì´ë¯¸ ì²˜ë¦¬ëœ ì˜ìƒ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° (ë„ë©”ì¸ë³„ ë¡œê·¸)"""
    log_path = os.path.join(LOG_ROOT, f"processed_log_{domain}.csv")
    if os.path.exists(log_path):
        return set(pd.read_csv(log_path)["video_id"].tolist())
    return set()


def append_processed_id(domain, video_id):
    """ì²˜ë¦¬ ì™„ë£Œëœ ì˜ìƒ IDë¥¼ ë¡œê·¸ì— ì¶”ê°€"""
    os.makedirs(LOG_ROOT, exist_ok=True)
    log_path = os.path.join(LOG_ROOT, f"processed_log_{domain}.csv")
    df = pd.DataFrame({"video_id": [video_id]})
    mode = "a" if os.path.exists(log_path) else "w"
    header = not os.path.exists(log_path)
    df.to_csv(log_path, mode=mode, header=header, index=False)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# utils
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def timestamp_to_seconds(timestamp):
    """00:01:23.456 â†’ 83.456 ì´ˆ"""
    parts = timestamp.split(':')
    hours = int(parts[0])
    minutes = int(parts[1])
    seconds = float(parts[2])
    return hours * 3600 + minutes * 60 + seconds


def clean_text(text: str):
    """í…ìŠ¤íŠ¸ ì •ì œ"""
    # [Music], [Applause] ë“± ì œê±°
    text = re.sub(r'\[.*?\]', '', text)
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VTT íŒŒì‹± (ê°œì„ )
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_vtt_file(vtt_path: str):
    """ë‹¨ì¼ VTT íŒŒì¼ì„ DataFrame í˜•íƒœë¡œ ë³€í™˜"""
    video_id = os.path.basename(vtt_path).split(".")[0]
    records = []
    
    try:
        for caption in webvtt.read(vtt_path):
            text = caption.text.strip().replace('\n', ' ')
            if len(text.split()) >= 2:
                records.append({
                    "video_id": video_id,
                    "start": caption.start,
                    "end": caption.end,
                    "start_sec": timestamp_to_seconds(caption.start),
                    "end_sec": timestamp_to_seconds(caption.end),
                    "text": text
                })
    except Exception as e:
        print(f"âš ï¸ {vtt_path} íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    return pd.DataFrame(records)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¤‘ë³µ ì œê±° ë¡œì§ (ê°œì„ )
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_overlap_prefix(prev_words, curr_words):
    """ì´ì „ í–‰ê³¼ í˜„ì¬ í–‰ ê°„ ì¤‘ë³µ êµ¬ê°„ íƒìƒ‰"""
    max_overlap = 0
    min_len = min(len(prev_words), len(curr_words))
    for i in range(1, min_len + 1):
        if prev_words[-i:] == curr_words[:i]:
            max_overlap = i
    return max_overlap


def remove_sequential_overlap(texts):
    """
    ìˆœì°¨ì ìœ¼ë¡œ ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ì¤‘ë³µ ì œê±° ë° ë³‘í•©
    
    Input:  ["at some point you have", "you have to believe", "believe something"]
    Output: "at some point you have to believe something"
    """
    if not texts:
        return ""
    
    result_words = texts[0].lower().split()
    
    for i in range(1, len(texts)):
        curr_words = texts[i].lower().split()
        
        # ì´ì „ ê²°ê³¼ì™€ í˜„ì¬ í…ìŠ¤íŠ¸ì˜ ì¤‘ë³µ ì°¾ê¸°
        overlap = get_overlap_prefix(result_words, curr_words)
        
        # ì¤‘ë³µ ì œê±° í›„ ì¶”ê°€
        new_words = curr_words[overlap:] if overlap > 0 else curr_words
        result_words.extend(new_words)
    
    return ' '.join(result_words)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹œê°„ ìœˆë„ìš° ë³‘í•© (í•µì‹¬ ì¶”ê°€)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def merge_by_time_window(df: pd.DataFrame, window_seconds=25):
    """
    ì‹œê°„ ìœˆë„ìš° ë‹¨ìœ„ë¡œ ìë§‰ ë³‘í•©
    
    Args:
        df: ì›ë³¸ ìë§‰ DataFrame
        window_seconds: ë³‘í•© ì‹œê°„ ìœˆë„ìš° (ì´ˆ)
    
    Returns:
        ë³‘í•©ëœ DataFrame (start, end, text)
    """
    if df.empty:
        return pd.DataFrame()
    
    merged_segments = []
    current_segment = {
        'start': df.iloc[0]['start'],
        'start_sec': df.iloc[0]['start_sec'],
        'end': df.iloc[0]['end'],
        'end_sec': df.iloc[0]['end_sec'],
        'texts': [df.iloc[0]['text']]
    }
    
    for idx in range(1, len(df)):
        row = df.iloc[idx]
        
        # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ ê¸¸ì´ ê³„ì‚°
        segment_duration = row['start_sec'] - current_segment['start_sec']
        
        # Pause ê¸¸ì´ ê³„ì‚°
        pause = row['start_sec'] - current_segment['end_sec']
        
        # ë³‘í•© ì¢…ë£Œ ì¡°ê±´
        # 1. ì‹œê°„ ìœˆë„ìš° ì´ˆê³¼
        # 2. ê¸´ pause (3ì´ˆ ì´ìƒ)
        if segment_duration >= window_seconds or pause > 3.0:
            # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
            merged_text = remove_sequential_overlap(current_segment['texts'])
            merged_text = clean_text(merged_text)
            
            # ìµœì†Œ 10ë‹¨ì–´ ì´ìƒë§Œ ì €ì¥
            if merged_text and len(merged_text.split()) >= 10:
                merged_segments.append({
                    'start': current_segment['start'],
                    'end': current_segment['end'],
                    'text': merged_text
                })
            
            # ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì‹œì‘
            current_segment = {
                'start': row['start'],
                'start_sec': row['start_sec'],
                'end': row['end'],
                'end_sec': row['end_sec'],
                'texts': [row['text']]
            }
        else:
            # í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì— ì¶”ê°€
            current_segment['texts'].append(row['text'])
            current_segment['end'] = row['end']
            current_segment['end_sec'] = row['end_sec']
    
    # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬
    if current_segment['texts']:
        merged_text = remove_sequential_overlap(current_segment['texts'])
        merged_text = clean_text(merged_text)
        
        if merged_text and len(merged_text.split()) >= 10:
            merged_segments.append({
                'start': current_segment['start'],
                'end': current_segment['end'],
                'text': merged_text
            })
    
    return pd.DataFrame(merged_segments)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# íŒŒì¼ ë‹¨ìœ„ ì²˜ë¦¬ (ê°œì„ )
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_single_video(domain, vtt_path, window_seconds=25):
    """ë‹¨ì¼ ì˜ìƒ ì „ì²˜ë¦¬ (ì‹œê°„ ìœˆë„ìš° ë³‘í•©)"""
    vid = os.path.splitext(os.path.basename(vtt_path))[0]
    print(f"\nğŸ¬ [{domain}] {vid} ì²˜ë¦¬ ì¤‘...")
    
    # 1. VTT íŒŒì‹±
    df = parse_vtt_file(vtt_path)
    if df.empty:
        print(f"âš ï¸ {vid}: ìë§‰ ë¹„ì–´ ìˆìŒ, ê±´ë„ˆëœ€")
        return
    
    print(f"   ğŸ“„ ì›ë³¸: {len(df)}ì¤„")
    
    # 2. ì‹œê°„ ìœˆë„ìš° ë³‘í•©
    df_merged = merge_by_time_window(df, window_seconds=window_seconds)
    
    if df_merged.empty:
        print(f"âš ï¸ {vid}: ë³‘í•© í›„ ë°ì´í„° ì—†ìŒ, ê±´ë„ˆëœ€")
        return
    
    print(f"   â±  {window_seconds}ì´ˆ ë³‘í•©: {len(df)}ì¤„ â†’ {len(df_merged)}ì„¸ê·¸ë¨¼íŠ¸")
    
    # 3. ìµœì¢… ì €ì¥
    out_dir = os.path.join(CLEAN_ROOT, domain)
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, f"{vid}.csv")
    
    df_merged.to_csv(out_path, index=False, encoding="utf-8-sig")
    
    append_processed_id(domain, vid)
    print(f"âœ… ì €ì¥: {out_path} ({len(df_merged)}ì„¸ê·¸ë¨¼íŠ¸)")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë„ë©”ì¸ ë‹¨ìœ„ ì²˜ë¦¬ (ê°œì„ )
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_domain(domain, window_seconds=25):
    """í•˜ë‚˜ì˜ ë„ë©”ì¸ ë‚´ ëª¨ë“  ì˜ìƒ ì²˜ë¦¬"""
    domain_raw_dir = os.path.join(RAW_ROOT, domain)
    if not os.path.exists(domain_raw_dir):
        print(f"âš ï¸ {domain_raw_dir} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœ€.")
        return
    
    vtts = [f for f in os.listdir(domain_raw_dir) if f.endswith(".vtt")]
    processed = get_processed_ids(domain)
    new_vtts = [f for f in vtts if os.path.splitext(f)[0] not in processed]
    
    if not new_vtts:
        print(f"âœ¨ [{domain}] ëª¨ë“  ì˜ìƒì´ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“‚ ë„ë©”ì¸: {domain} ({len(new_vtts)}ê°œ ì‹ ê·œ)")
    print(f"â±  ì‹œê°„ ìœˆë„ìš°: {window_seconds}ì´ˆ")
    
    for vtt in new_vtts:
        process_single_video(domain, os.path.join(domain_raw_dir, vtt), 
                           window_seconds=window_seconds)


def process_all_domains(window_seconds=25):
    """ëª¨ë“  ë„ë©”ì¸ í´ë” ìˆœíšŒ"""
    domains = [d for d in os.listdir(RAW_ROOT) 
               if os.path.isdir(os.path.join(RAW_ROOT, d))]
    
    if not domains:
        print("âŒ ì²˜ë¦¬í•  ë„ë©”ì¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("="*80)
    print(f"ìë§‰ ì „ì²˜ë¦¬ ì‹œì‘ (ì‹œê°„ ìœˆë„ìš°: {window_seconds}ì´ˆ)")
    print("="*80)
    
    for domain in domains:
        process_domain(domain, window_seconds=window_seconds)
    
    print("\n" + "="*80)
    print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print("="*80)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰ë¶€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ìë§‰ ì „ì²˜ë¦¬ (ì‹œê°„ ìœˆë„ìš° ë³‘í•©)"
    )
    parser.add_argument(
        "--window", 
        type=int, 
        default=25,
        help="ë³‘í•© ì‹œê°„ ìœˆë„ìš° (ì´ˆ), ê¸°ë³¸ 25ì´ˆ"
    )
    parser.add_argument(
        "--domain",
        type=str,
        help="íŠ¹ì • ë„ë©”ì¸ë§Œ ì²˜ë¦¬"
    )
    args = parser.parse_args()
    
    if args.domain:
        process_domain(args.domain, window_seconds=args.window)
    else:
        process_all_domains(window_seconds=args.window)
